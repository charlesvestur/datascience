{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import dmatrices, dmatrix\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LassoLars, LassoLarsCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train allstate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test allstate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 132)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "      <th>cat19</th>\n",
       "      <th>cat20</th>\n",
       "      <th>cat21</th>\n",
       "      <th>cat22</th>\n",
       "      <th>cat23</th>\n",
       "      <th>cat24</th>\n",
       "      <th>cat25</th>\n",
       "      <th>cat26</th>\n",
       "      <th>cat27</th>\n",
       "      <th>cat28</th>\n",
       "      <th>cat29</th>\n",
       "      <th>cat30</th>\n",
       "      <th>cat31</th>\n",
       "      <th>cat32</th>\n",
       "      <th>cat33</th>\n",
       "      <th>cat34</th>\n",
       "      <th>cat35</th>\n",
       "      <th>cat36</th>\n",
       "      <th>cat37</th>\n",
       "      <th>cat38</th>\n",
       "      <th>cat39</th>\n",
       "      <th>cat40</th>\n",
       "      <th>cat41</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat43</th>\n",
       "      <th>cat44</th>\n",
       "      <th>cat45</th>\n",
       "      <th>cat46</th>\n",
       "      <th>cat47</th>\n",
       "      <th>cat48</th>\n",
       "      <th>cat49</th>\n",
       "      <th>cat50</th>\n",
       "      <th>cat51</th>\n",
       "      <th>cat52</th>\n",
       "      <th>cat53</th>\n",
       "      <th>cat54</th>\n",
       "      <th>cat55</th>\n",
       "      <th>cat56</th>\n",
       "      <th>cat57</th>\n",
       "      <th>cat58</th>\n",
       "      <th>cat59</th>\n",
       "      <th>cat60</th>\n",
       "      <th>cat61</th>\n",
       "      <th>cat62</th>\n",
       "      <th>cat63</th>\n",
       "      <th>cat64</th>\n",
       "      <th>cat65</th>\n",
       "      <th>cat66</th>\n",
       "      <th>cat67</th>\n",
       "      <th>cat68</th>\n",
       "      <th>cat69</th>\n",
       "      <th>cat70</th>\n",
       "      <th>cat71</th>\n",
       "      <th>cat72</th>\n",
       "      <th>cat73</th>\n",
       "      <th>cat74</th>\n",
       "      <th>cat75</th>\n",
       "      <th>cat76</th>\n",
       "      <th>cat77</th>\n",
       "      <th>cat78</th>\n",
       "      <th>cat79</th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat81</th>\n",
       "      <th>cat82</th>\n",
       "      <th>cat83</th>\n",
       "      <th>cat84</th>\n",
       "      <th>cat85</th>\n",
       "      <th>cat86</th>\n",
       "      <th>cat87</th>\n",
       "      <th>cat88</th>\n",
       "      <th>cat89</th>\n",
       "      <th>cat90</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat92</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat96</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat102</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>BU</td>\n",
       "      <td>BC</td>\n",
       "      <td>C</td>\n",
       "      <td>AS</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>LB</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>0.245921</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CQ</td>\n",
       "      <td>A</td>\n",
       "      <td>AV</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DP</td>\n",
       "      <td>0.330514</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>O</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>AB</td>\n",
       "      <td>DK</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>AF</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>GK</td>\n",
       "      <td>0.261841</td>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DJ</td>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>K</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "      <td>0.273204</td>\n",
       "      <td>0.159990</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12 cat13  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B     A     B     A     A   \n",
       "1   2    A    B    A    A    A    A    A    A    B     B     A     A     A   \n",
       "2   5    A    B    A    A    B    A    A    A    B     B     B     B     B   \n",
       "3  10    B    B    A    B    A    A    A    A    B     A     A     A     A   \n",
       "4  11    A    B    A    B    A    A    A    A    B     B     A     B     A   \n",
       "\n",
       "  cat14 cat15 cat16 cat17 cat18 cat19 cat20 cat21 cat22 cat23 cat24 cat25  \\\n",
       "0     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     B     A     A   \n",
       "\n",
       "  cat26 cat27 cat28 cat29 cat30 cat31 cat32 cat33 cat34 cat35 cat36 cat37  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat38 cat39 cat40 cat41 cat42 cat43 cat44 cat45 cat46 cat47 cat48 cat49  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat50 cat51 cat52 cat53 cat54 cat55 cat56 cat57 cat58 cat59 cat60 cat61  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat62 cat63 cat64 cat65 cat66 cat67 cat68 cat69 cat70 cat71 cat72 cat73  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     B   \n",
       "4     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "\n",
       "  cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81 cat82 cat83 cat84 cat85  \\\n",
       "0     A     B     A     D     B     B     D     D     B     D     C     B   \n",
       "1     A     A     A     D     B     B     D     D     A     B     C     B   \n",
       "2     A     A     A     D     B     B     B     D     B     D     C     B   \n",
       "3     A     A     A     D     B     B     D     D     D     B     C     B   \n",
       "4     A     A     A     D     B     D     B     D     B     B     C     B   \n",
       "\n",
       "  cat86 cat87 cat88 cat89 cat90 cat91 cat92 cat93 cat94 cat95 cat96 cat97  \\\n",
       "0     D     B     A     A     A     A     A     D     B     C     E     A   \n",
       "1     D     B     A     A     A     A     A     D     D     C     E     E   \n",
       "2     B     B     A     A     A     A     A     D     D     C     E     E   \n",
       "3     D     B     A     A     A     A     A     D     D     C     E     E   \n",
       "4     B     C     A     A     A     B     H     D     B     D     E     E   \n",
       "\n",
       "  cat98 cat99 cat100 cat101 cat102 cat103 cat104 cat105 cat106 cat107 cat108  \\\n",
       "0     C     T      B      G      A      A      I      E      G      J      G   \n",
       "1     D     T      L      F      A      A      E      E      I      K      K   \n",
       "2     A     D      L      O      A      B      E      F      H      F      A   \n",
       "3     D     T      I      D      A      A      E      E      I      K      K   \n",
       "4     A     P      F      J      A      A      D      E      K      G      B   \n",
       "\n",
       "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116     cont1     cont2  \\\n",
       "0     BU     BC      C     AS      S      A      O     LB  0.726300  0.245921   \n",
       "1     BI     CQ      A     AV     BM      A      O     DP  0.330514  0.737068   \n",
       "2     AB     DK      A      C     AF      A      I     GK  0.261841  0.358319   \n",
       "3     BI     CS      C      N     AE      A      O     DJ  0.321594  0.555782   \n",
       "4      H      C      C      Y     BM      A      K     CK  0.273204  0.159990   \n",
       "\n",
       "      cont3     cont4     cont5     cont6     cont7    cont8    cont9  \\\n",
       "0  0.187583  0.789639  0.310061  0.718367  0.335060  0.30260  0.67135   \n",
       "1  0.592681  0.614134  0.885834  0.438917  0.436585  0.60087  0.35127   \n",
       "2  0.484196  0.236924  0.397069  0.289648  0.315545  0.27320  0.26076   \n",
       "3  0.527991  0.373816  0.422268  0.440945  0.391128  0.31796  0.32128   \n",
       "4  0.527991  0.473202  0.704268  0.178193  0.247408  0.24564  0.22089   \n",
       "\n",
       "    cont10    cont11    cont12    cont13    cont14     loss  \n",
       "0  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n",
       "1  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n",
       "2  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n",
       "3  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n",
       "4  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125546, 131)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "      <th>cat19</th>\n",
       "      <th>cat20</th>\n",
       "      <th>cat21</th>\n",
       "      <th>cat22</th>\n",
       "      <th>cat23</th>\n",
       "      <th>cat24</th>\n",
       "      <th>cat25</th>\n",
       "      <th>cat26</th>\n",
       "      <th>cat27</th>\n",
       "      <th>cat28</th>\n",
       "      <th>cat29</th>\n",
       "      <th>cat30</th>\n",
       "      <th>cat31</th>\n",
       "      <th>cat32</th>\n",
       "      <th>cat33</th>\n",
       "      <th>cat34</th>\n",
       "      <th>cat35</th>\n",
       "      <th>cat36</th>\n",
       "      <th>cat37</th>\n",
       "      <th>cat38</th>\n",
       "      <th>cat39</th>\n",
       "      <th>cat40</th>\n",
       "      <th>cat41</th>\n",
       "      <th>cat42</th>\n",
       "      <th>cat43</th>\n",
       "      <th>cat44</th>\n",
       "      <th>cat45</th>\n",
       "      <th>cat46</th>\n",
       "      <th>cat47</th>\n",
       "      <th>cat48</th>\n",
       "      <th>cat49</th>\n",
       "      <th>cat50</th>\n",
       "      <th>cat51</th>\n",
       "      <th>cat52</th>\n",
       "      <th>cat53</th>\n",
       "      <th>cat54</th>\n",
       "      <th>cat55</th>\n",
       "      <th>cat56</th>\n",
       "      <th>cat57</th>\n",
       "      <th>cat58</th>\n",
       "      <th>cat59</th>\n",
       "      <th>cat60</th>\n",
       "      <th>cat61</th>\n",
       "      <th>cat62</th>\n",
       "      <th>cat63</th>\n",
       "      <th>cat64</th>\n",
       "      <th>cat65</th>\n",
       "      <th>cat66</th>\n",
       "      <th>cat67</th>\n",
       "      <th>cat68</th>\n",
       "      <th>cat69</th>\n",
       "      <th>cat70</th>\n",
       "      <th>cat71</th>\n",
       "      <th>cat72</th>\n",
       "      <th>cat73</th>\n",
       "      <th>cat74</th>\n",
       "      <th>cat75</th>\n",
       "      <th>cat76</th>\n",
       "      <th>cat77</th>\n",
       "      <th>cat78</th>\n",
       "      <th>cat79</th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat81</th>\n",
       "      <th>cat82</th>\n",
       "      <th>cat83</th>\n",
       "      <th>cat84</th>\n",
       "      <th>cat85</th>\n",
       "      <th>cat86</th>\n",
       "      <th>cat87</th>\n",
       "      <th>cat88</th>\n",
       "      <th>cat89</th>\n",
       "      <th>cat90</th>\n",
       "      <th>cat91</th>\n",
       "      <th>cat92</th>\n",
       "      <th>cat93</th>\n",
       "      <th>cat94</th>\n",
       "      <th>cat95</th>\n",
       "      <th>cat96</th>\n",
       "      <th>cat97</th>\n",
       "      <th>cat98</th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat102</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>BC</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>AX</td>\n",
       "      <td>A</td>\n",
       "      <td>Q</td>\n",
       "      <td>HG</td>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.377724</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>CO</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>HK</td>\n",
       "      <td>0.634734</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.654310</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.689039</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>U</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "      <td>0.290813</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.711159</td>\n",
       "      <td>0.412789</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CR</td>\n",
       "      <td>A</td>\n",
       "      <td>AY</td>\n",
       "      <td>AJ</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>DJ</td>\n",
       "      <td>0.268622</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>0.348867</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>AB</td>\n",
       "      <td>EG</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>C</td>\n",
       "      <td>J</td>\n",
       "      <td>HA</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.263570</td>\n",
       "      <td>0.696873</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.359572</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10 cat11 cat12 cat13  \\\n",
       "0   4    A    B    A    A    A    A    A    A    B     A     B     A     A   \n",
       "1   6    A    B    A    B    A    A    A    A    B     A     A     A     A   \n",
       "2   9    A    B    A    B    B    A    B    A    B     B     A     B     B   \n",
       "3  12    A    A    A    A    B    A    A    A    A     A     A     A     A   \n",
       "4  15    B    A    A    A    A    B    A    A    A     A     A     A     A   \n",
       "\n",
       "  cat14 cat15 cat16 cat17 cat18 cat19 cat20 cat21 cat22 cat23 cat24 cat25  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     B     B     A   \n",
       "2     B     A     A     A     A     A     A     A     A     B     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat26 cat27 cat28 cat29 cat30 cat31 cat32 cat33 cat34 cat35 cat36 cat37  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat38 cat39 cat40 cat41 cat42 cat43 cat44 cat45 cat46 cat47 cat48 cat49  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     B     B     A     A     A     A     A     A     A     A     A     A   \n",
       "3     B     A     A     B     A     A     A     A     A     A     A     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat50 cat51 cat52 cat53 cat54 cat55 cat56 cat57 cat58 cat59 cat60 cat61  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "2     A     A     A     A     A     A     A     B     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "4     B     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat62 cat63 cat64 cat65 cat66 cat67 cat68 cat69 cat70 cat71 cat72 cat73  \\\n",
       "0     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "1     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "2     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "3     A     A     A     A     A     A     A     A     A     A     B     A   \n",
       "4     A     A     A     A     A     A     A     A     A     A     A     A   \n",
       "\n",
       "  cat74 cat75 cat76 cat77 cat78 cat79 cat80 cat81 cat82 cat83 cat84 cat85  \\\n",
       "0     A     A     A     D     B     B     D     D     B     B     C     B   \n",
       "1     A     B     A     D     B     B     D     D     B     B     C     B   \n",
       "2     A     A     B     D     B     B     B     B     B     D     C     B   \n",
       "3     A     A     A     D     B     D     B     D     B     B     A     B   \n",
       "4     A     A     A     D     B     B     D     D     B     B     C     B   \n",
       "\n",
       "  cat86 cat87 cat88 cat89 cat90 cat91 cat92 cat93 cat94 cat95 cat96 cat97  \\\n",
       "0     D     B     A     A     A     A     A     D     C     C     E     C   \n",
       "1     B     B     A     A     A     A     A     D     D     D     E     A   \n",
       "2     B     B     A     B     A     A     A     D     D     C     E     E   \n",
       "3     D     D     A     A     A     G     H     D     D     C     E     E   \n",
       "4     B     B     A     A     A     A     A     D     B     D     E     A   \n",
       "\n",
       "  cat98 cat99 cat100 cat101 cat102 cat103 cat104 cat105 cat106 cat107 cat108  \\\n",
       "0     D     T      H      G      A      A      G      E      I      L      K   \n",
       "1     A     P      B      D      A      A      G      G      G      F      B   \n",
       "2     A     D      G      Q      A      D      D      E      J      G      A   \n",
       "3     D     T      G      A      A      D      E      E      I      K      K   \n",
       "4     A     P      A      A      A      A      F      E      G      E      B   \n",
       "\n",
       "  cat109 cat110 cat111 cat112 cat113 cat114 cat115 cat116     cont1     cont2  \\\n",
       "0     BI     BC      A      J     AX      A      Q     HG  0.321594  0.299102   \n",
       "1     BI     CO      E      G      X      A      L     HK  0.634734  0.620805   \n",
       "2     BI     CS      C      U     AE      A      K     CK  0.290813  0.737068   \n",
       "3     BI     CR      A     AY     AJ      A      P     DJ  0.268622  0.681761   \n",
       "4     AB     EG      A      E      I      C      J     HA  0.553846  0.299102   \n",
       "\n",
       "      cont3     cont4     cont5     cont6     cont7    cont8    cont9  \\\n",
       "0  0.246911  0.402922  0.281143  0.466591  0.317681  0.61229  0.34365   \n",
       "1  0.654310  0.946616  0.836443  0.482425  0.443760  0.71330  0.51890   \n",
       "2  0.711159  0.412789  0.718531  0.212308  0.325779  0.29758  0.34365   \n",
       "3  0.592681  0.354893  0.397069  0.369930  0.342355  0.40028  0.33237   \n",
       "4  0.263570  0.696873  0.302678  0.398862  0.391833  0.23688  0.43731   \n",
       "\n",
       "    cont10    cont11    cont12    cont13    cont14  \n",
       "0  0.38016  0.377724  0.369858  0.704052  0.392562  \n",
       "1  0.60401  0.689039  0.675759  0.453468  0.208045  \n",
       "2  0.30529  0.245410  0.241676  0.258586  0.297232  \n",
       "3  0.31480  0.348867  0.341872  0.592264  0.555955  \n",
       "4  0.50556  0.359572  0.352251  0.301535  0.825823  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_loss = df_test.copy()\n",
    "df_test_loss[\"loss\"] = 0\n",
    "df_concat = pd.concat([df_train, df_test_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dmat = ''\n",
    "columns = df_train.columns[1:-1]\n",
    "\n",
    "for i, c in enumerate(columns[:-1]):\n",
    "    if c[:3] == 'cat':\n",
    "        dmat += 'C(' + c + ') + '\n",
    "    else:\n",
    "        dmat += c + '+ '\n",
    "\n",
    "dmat += columns[-1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_concat, X_concat = dmatrices('loss ~ ' + dmat, df_concat, return_type=\"dataframe\")\n",
    "#X_test = dmatrix(dmat, df_concat, return_type=\"dataframe\")\n",
    "train_slice = df_train.shape[0]\n",
    "y_train, X_train, X_test = y_concat[:train_slice], X_concat[:train_slice], X_concat[train_slice:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_init, X_train_init = dmatrices('loss ~ ' + dmat, df_train, return_type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_init = dmatrix(dmat, df_test, return_type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_columns = list(set(X_train_init.columns) & set(X_test_init.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 1038)\n",
      "(188318, 1038)\n",
      "(188318, 964)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_init.shape)\n",
    "X_train = X_train_init.ix[:,common_columns]\n",
    "print(X_train_init.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.558e-01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.339e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.314e-01, with an active set of 87 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.275e-01, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=7.122e-02, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.661e-02, with an active set of 166 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.496e-02, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=6.180e-02, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=6.180e-02, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 196 iterations, alpha=5.402e-02, previous alpha=5.204e-02, with an active set of 193 regressors.\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.685e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.602e-01, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.435e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.048e-01, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.484e-02, with an active set of 157 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.589e-02, with an active set of 176 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=5.339e-02, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 184 iterations, alpha=5.469e-02, previous alpha=5.317e-02, with an active set of 183 regressors.\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.898e-01, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.364e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.084e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=6.676e-02, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=6.071e-02, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=6.071e-02, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=5.046e-02, with an active set of 211 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=4.950e-02, with an active set of 215 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=4.560e-02, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 240 iterations, alpha=4.304e-02, previous alpha=4.288e-02, with an active set of 235 regressors.\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.034e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.056e-01, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=8.569e-02, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=5.842e-02, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LassoLarsCV()\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test_init.ix[:,common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125546, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1149.483055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2028.637308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>11297.746321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>5953.671839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>235.054126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          loss\n",
       "0   4   1149.483055\n",
       "1   6   2028.637308\n",
       "2   9  11297.746321\n",
       "3  12   5953.671839\n",
       "4  15    235.054126"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(data={'id': df_test['id'].values, 'loss': np.ravel(y_pred)})\n",
    "print(df_pred.shape)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pred.to_csv('pred allstate',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_train_init, y_train_init, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.401e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.701e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.272e-01, with an active set of 112 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=1.144e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.688e-02, with an active set of 159 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=7.700e-02, with an active set of 182 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=7.555e-02, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=5.722e-02, with an active set of 232 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 268 iterations, alpha=4.777e-02, previous alpha=4.682e-02, with an active set of 261 regressors.\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.038e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.838e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.649e-01, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.540e-01, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.245e-02, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.245e-02, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=7.639e-02, with an active set of 180 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=7.510e-02, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=7.068e-02, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=6.050e-02, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.931e-02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=4.711e-02, with an active set of 259 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 270 iterations, alpha=4.673e-02, previous alpha=4.537e-02, with an active set of 265 regressors.\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.736e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.476e-01, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=1.778e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.738e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.980e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.656e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.543e-01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.425e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.184e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.184e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=9.927e-02, with an active set of 141 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=9.709e-02, with an active set of 144 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=9.212e-02, with an active set of 148 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 154 iterations, alpha=9.190e-02, previous alpha=9.078e-02, with an active set of 153 regressors.\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.396e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.312e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.373e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.226e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.175e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.153e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.049e-01, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=9.166e-02, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=9.085e-02, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 142 iterations, alpha=8.716e-02, previous alpha=8.439e-02, with an active set of 141 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LassoLarsCV()\n",
    "clf = clf.fit(X_sub_train, y_sub_train)\n",
    "y_sub_test_pred = clf.predict(X_sub_test)\n",
    "print(mean_absolute_error(y_sub_test, y_sub_test_pred))\n",
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1734.5801492141036"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X_sub_train, y_sub_train)\n",
    "y_sub_test_pred = clf.predict(X_sub_test)\n",
    "mean_absolute_error(y_sub_test, y_sub_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1411.6610355534153"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='ls')\n",
    "clf = clf.fit(X_sub_train, np.ravel(y_sub_train))\n",
    "y_sub_test_pred = clf.predict(X_sub_test)\n",
    "mean_absolute_error(y_sub_test, y_sub_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. , -0.9, -0.8, -0.7, -0.6, -0.5, -0.4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_pos = np.arange(-1.,-0.3,0.1)\n",
    "alpha_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.396e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.312e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.373e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.226e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.175e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.153e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.049e-01, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=9.166e-02, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=9.085e-02, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 142 iterations, alpha=8.716e-02, previous alpha=8.439e-02, with an active set of 141 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with -1.0: 1303.99\n",
      "MAE with -0.9: 1303.99\n",
      "MAE with -0.8: 1303.99\n",
      "MAE with -0.7: 1303.99\n",
      "MAE with -0.6: 1303.99\n",
      "MAE with -0.5: 1303.99\n",
      "MAE with -0.4: 1303.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{-1.0: 1303.9851804523257,\n",
       " -0.90000000000000002: 1303.9851804523257,\n",
       " -0.80000000000000004: 1303.9851804523257,\n",
       " -0.70000000000000007: 1303.9851804523257,\n",
       " -0.60000000000000009: 1303.9851804523257,\n",
       " -0.50000000000000011: 1303.9851804523257,\n",
       " -0.40000000000000013: 1303.9851804523257}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for a in alpha_pos:\n",
    "    clf = LassoLars(alpha=a)\n",
    "    clf.fit(X_sub_train, y_sub_train)\n",
    "    y_sub_pred = clf.predict(X_sub_test)\n",
    "    mae = mean_absolute_error(y_sub_test, y_sub_pred)\n",
    "    results[a] = mae\n",
    "    print(\"MAE with %s: %0.2f\" % (a, mae))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for a in alpha_pos:\n",
    "    clf = Ridge(alpha=a)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='mean_absolute_error')\n",
    "    results[a] = scores.mean()\n",
    "    #scores\n",
    "    print(\"MAE with %s: %0.2f (+/- %0.2f)\" % (a, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_sub_pred = clf.predict(X_sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1304.2961829972985"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_sub_test, y_sub_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
